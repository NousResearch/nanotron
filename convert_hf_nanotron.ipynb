{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.testing import assert_close\n",
    "\n",
    "import os\n",
    "\n",
    "dtype = torch.bfloat16\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"MASTER_ADDR\"] = \"0.0.0.0\"\n",
    "os.environ[\"MASTER_PORT\"] = \"6000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LLAMA = \"/mloscratch/homes/solergib/models/Meta-Llama-3-8B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/solergib/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 13.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(PATH_TO_LLAMA, torch_dtype=dtype, attn_implementation=\"flash_attention_2\").to(device)\n",
    "# print(hf_model)\n",
    "# print(hf_model.config)\n",
    "#print(hf_model.model.rotary_emb.ori_inv_freq.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128001,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.44.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaConfig\n",
    "hf_config = LlamaConfig.from_pretrained(PATH_TO_LLAMA)\n",
    "print(hf_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nanotron.config import ParallelismArgs\n",
    "from nanotron.parallel import ParallelContext\n",
    "from nanotron.parallel.pipeline_parallel.engine import AllForwardAllBackwardPipelineEngine\n",
    "from nanotron.parallel.tensor_parallel.nn import TensorParallelLinearMode\n",
    "\n",
    "DP = 1\n",
    "PP = 1\n",
    "TP = 1\n",
    "\n",
    "parallel_config = ParallelismArgs(\n",
    "    dp=DP,\n",
    "    pp=PP,\n",
    "    tp=TP,\n",
    "    pp_engine=AllForwardAllBackwardPipelineEngine(),\n",
    "    tp_mode=TensorParallelLinearMode.ALL_REDUCE,\n",
    "    tp_linear_async_communication=False,\n",
    ")\n",
    "assert (\n",
    "    parallel_config.tp_mode == TensorParallelLinearMode.ALL_REDUCE\n",
    "    and parallel_config.tp_linear_async_communication is False\n",
    ")\n",
    "\n",
    "parallel_context = ParallelContext(\n",
    "    data_parallel_size=parallel_config.dp,\n",
    "    pipeline_parallel_size=parallel_config.pp,\n",
    "    tensor_parallel_size=parallel_config.tp,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nanotron.config.models_config import LlamaConfig as LlamaConfigNanotron\n",
    "\n",
    "nanotron_config = LlamaConfigNanotron(\n",
    "    bos_token_id=hf_config.bos_token_id,\n",
    "    eos_token_id=hf_config.eos_token_id,\n",
    "    hidden_act=hf_config.hidden_act,\n",
    "    hidden_size=hf_config.hidden_size,\n",
    "    initializer_range=hf_config.initializer_range,\n",
    "    intermediate_size=hf_config.intermediate_size,\n",
    "    is_llama_config=True,\n",
    "    max_position_embeddings=hf_config.max_position_embeddings,\n",
    "    num_attention_heads=hf_config.num_attention_heads,\n",
    "    num_hidden_layers=hf_config.num_hidden_layers,\n",
    "    num_key_value_heads=hf_config.num_key_value_heads,\n",
    "    pad_token_id=None,\n",
    "    pretraining_tp=hf_config.pretraining_tp,\n",
    "    rms_norm_eps=hf_config.rms_norm_eps,\n",
    "    rope_scaling=hf_config.rope_scaling,\n",
    "    rope_theta=hf_config.rope_theta,\n",
    "    rope_interleaved=False,\n",
    "    tie_word_embeddings=hf_config.tie_word_embeddings,\n",
    "    use_cache=hf_config.use_cache,\n",
    "    vocab_size=hf_config.vocab_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "from nanotron.models.llama_sft import LlamaForSFT\n",
    "from nanotron.models import build_model\n",
    "\n",
    "nanotron_model = build_model(\n",
    "        model_builder=lambda: LlamaForSFT(\n",
    "            config=nanotron_config,\n",
    "            parallel_context=parallel_context,\n",
    "            parallel_config=parallel_config,\n",
    "            random_states=None,\n",
    "        ),\n",
    "        parallel_context=parallel_context,\n",
    "        dtype=dtype,\n",
    "        device=device,\n",
    ")\n",
    "# print(nanotron_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nanotron.trainer import mark_tied_parameters\n",
    "\n",
    "mark_tied_parameters(model=nanotron_model, parallel_context=parallel_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShardedInfo(global_ranks=(0,), local_global_slices_pairs=(SlicesPair(local_slices=(slice(None, None, None), slice(None, None, None)), global_slices=(slice(0, 128256, None), slice(None, None, None))),), unsharded_shape=(128256, 4096))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nanotron_model.model.token_position_embeddings.pp_block.token_embedding.weight.get_sharded_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nanotron_model.model.token_position_embeddings.pp_block.token_embedding.weight.is_tied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final script\n",
    "# TODO Añadir variables de TP para splitear los parametros de las layers de HF\n",
    "# TODO Cargar modelo HF en cpu y copiar desde ahi\n",
    "\n",
    "\n",
    "# Token embeddings\n",
    "assert nanotron_model.model.token_position_embeddings.pp_block.token_embedding.weight.shape == hf_model.model.embed_tokens.weight.shape\n",
    "\n",
    "with torch.no_grad():\n",
    "    nanotron_model.model.token_position_embeddings.pp_block.token_embedding.weight.copy_(hf_model.model.embed_tokens.weight)#  = hf_model.model.embed_tokens.weight.data\n",
    "\n",
    "# Decoder layers\n",
    "for i in range(nanotron_config.num_hidden_layers):\n",
    "    # Input layer norm\n",
    "    assert hf_model.model.layers[i].input_layernorm.weight.shape == nanotron_model.model.decoder[i].pp_block.input_layernorm.weight.shape\n",
    "    with torch.no_grad():\n",
    "        nanotron_model.model.decoder[i].pp_block.input_layernorm.weight.copy_(hf_model.model.layers[i].input_layernorm.weight)#  = hf_model.model.layers[i].input_layernorm.weight\n",
    "    # Self attn\n",
    "    ## QKV\n",
    "    tmp_qkv_proj = torch.cat([\n",
    "        hf_model.model.layers[i].self_attn.q_proj.weight,\n",
    "        hf_model.model.layers[i].self_attn.k_proj.weight,\n",
    "        hf_model.model.layers[i].self_attn.v_proj.weight\n",
    "    ], dim = 0) \n",
    "    assert tmp_qkv_proj.shape == nanotron_model.model.decoder[i].pp_block.attn.qkv_proj.weight.shape\n",
    "    with torch.no_grad():\n",
    "        nanotron_model.model.decoder[i].pp_block.attn.qkv_proj.weight.copy_(tmp_qkv_proj)#  = tmp_qkv_proj # torch.nn.Parameter(tmp_qkv_proj)\n",
    "    \n",
    "    ## O\n",
    "    assert hf_model.model.layers[i].self_attn.o_proj.weight.shape == nanotron_model.model.decoder[i].pp_block.attn.o_proj.weight.shape\n",
    "    with torch.no_grad():\n",
    "        nanotron_model.model.decoder[i].pp_block.attn.o_proj.weight.copy_(hf_model.model.layers[i].self_attn.o_proj.weight)#  = hf_model.model.layers[i].self_attn.o_proj.weight\n",
    "    # MLP\n",
    "    ## Gate Up Proj\n",
    "    tmp_gate_up_proj = torch.cat([\n",
    "        hf_model.model.layers[i].mlp.gate_proj.weight,\n",
    "        hf_model.model.layers[i].mlp.up_proj.weight,\n",
    "    ], dim = 0)\n",
    "\n",
    "    assert tmp_gate_up_proj.shape == nanotron_model.model.decoder[i].pp_block.mlp.gate_up_proj.weight.shape\n",
    "    with torch.no_grad():\n",
    "        nanotron_model.model.decoder[i].pp_block.mlp.gate_up_proj.weight.copy_(tmp_gate_up_proj)#  = tmp_gate_up_proj\n",
    "    ## Down Proj\n",
    "    assert hf_model.model.layers[i].mlp.down_proj.weight.shape == nanotron_model.model.decoder[i].pp_block.mlp.down_proj.weight.shape\n",
    "    with torch.no_grad():\n",
    "        nanotron_model.model.decoder[i].pp_block.mlp.down_proj.weight.copy_(hf_model.model.layers[i].mlp.down_proj.weight)#  = hf_model.model.layers[i].mlp.down_proj.weight\n",
    "\n",
    "\n",
    "    # Post attn layer norm\n",
    "    assert hf_model.model.layers[i].post_attention_layernorm.weight.shape == nanotron_model.model.decoder[i].pp_block.post_attention_layernorm.weight.shape\n",
    "    with torch.no_grad():\n",
    "        nanotron_model.model.decoder[i].pp_block.post_attention_layernorm.weight.copy_(hf_model.model.layers[i].post_attention_layernorm.weight)#  = hf_model.model.layers[i].post_attention_layernorm.weight\n",
    "    \n",
    "# Last layer norm\n",
    "assert nanotron_model.model.final_layer_norm.pp_block.weight.shape == hf_model.model.norm.weight.shape\n",
    "with torch.no_grad():\n",
    "    nanotron_model.model.final_layer_norm.pp_block.weight.copy_(hf_model.model.norm.weight)#  = hf_model.model.norm.weight\n",
    "# LM_Head\n",
    "assert nanotron_model.model.lm_head.pp_block.weight.shape == hf_model.lm_head.weight.shape\n",
    "with torch.no_grad():\n",
    "    nanotron_model.model.lm_head.pp_block.weight.copy_(hf_model.lm_head.weight)# = hf_model.lm_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import importlib\n",
    "import nanotron\n",
    "importlib.reload(nanotron.data.chat_dataset)\n",
    "importlib.reload(nanotron.data.collator)\n",
    "\"\"\"\n",
    "\n",
    "from nanotron.data.chat_dataset import ChatDataset\n",
    "from nanotron.data.dataloader_builder import build_chat_dataloader\n",
    "\n",
    "train_dataset = ChatDataset(\n",
    "    dataset_path=\"Open-Orca/SlimOrca\",\n",
    "    tokenizer_name_or_path=PATH_TO_LLAMA,\n",
    "    sequence_length=2048,\n",
    "    train_on_completions_only=True,\n",
    "    remove_cross_attention=True,\n",
    "    split=\"train\",\n",
    "    conversation_column_name=\"conversations\",\n",
    "    dp_rank=parallel_context.dp_pg.rank(),\n",
    "    dp_ranks_size=parallel_context.dp_pg.size(),\n",
    ")\n",
    "\n",
    "# Prepare dataloader\n",
    "train_dataloader = build_chat_dataloader(\n",
    "    dataset=train_dataset,\n",
    "    sequence_length=2048,\n",
    "    parallel_context=parallel_context,\n",
    "    input_pp_rank=0,\n",
    "    output_pp_rank=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128000, 128006,  26380,  ...,  16686,     13, 128009]],\n",
       "        dtype=torch.int32),\n",
       " 'position_ids': tensor([[  0,   1,   2,  ..., 576, 577, 578]], dtype=torch.int32),\n",
       " 'label_ids': tensor([[128006,  26380, 128007,  ...,     13, 128009, 128001]],\n",
       "        dtype=torch.int32),\n",
       " 'label_mask': tensor([[False, False, False,  ...,  True,  True,  True]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert batch[\"input_ids\"].shape == batch[\"label_ids\"].shape \n",
    "assert batch[\"input_ids\"].shape == batch[\"position_ids\"].shape\n",
    "assert batch[\"input_ids\"].shape == batch[\"label_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForSFT(\n",
       "  (model): LlamaModel(\n",
       "    (token_position_embeddings): PipelineBlock(\n",
       "      pp_rank=0\n",
       "      (pp_block): Embedding(\n",
       "        (token_embedding): TensorParallelEmbedding(tp_rank=0, 128256, 4096, unsharded_num_embeddings=128256)\n",
       "        (position_embedding): LlamaRotaryEmbedding()\n",
       "      )\n",
       "    )\n",
       "    (decoder): ModuleList(\n",
       "      (0-31): 32 x PipelineBlock(\n",
       "        pp_rank=0\n",
       "        (pp_block): LlamaDecoderLayer(\n",
       "          (input_layernorm): TritonRMSNorm()\n",
       "          (attn): CausalSelfAttention(\n",
       "            (qkv_proj): TensorParallelColumnLinear(tp_rank=0, in_features=4096, out_features=6144, bias=False, unsharded_out_features=6144)\n",
       "            (o_proj): TensorParallelRowLinear(tp_rank=0, in_features=4096, out_features=4096, bias=False, unsharded_in_features=4096)\n",
       "          )\n",
       "          (post_attention_layernorm): TritonRMSNorm()\n",
       "          (mlp): MLP(\n",
       "            (gate_up_proj): TensorParallelColumnLinear(tp_rank=0, in_features=4096, out_features=28672, bias=False, unsharded_out_features=28672)\n",
       "            (down_proj): TensorParallelRowLinear(tp_rank=0, in_features=14336, out_features=4096, bias=False, unsharded_in_features=14336)\n",
       "            (split_silu_mul): GLUActivation(\n",
       "              (act): SiLUActivation()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): PipelineBlock(\n",
       "      pp_rank=0\n",
       "      (pp_block): TritonRMSNorm()\n",
       "    )\n",
       "    (lm_head): PipelineBlock(\n",
       "      pp_rank=0\n",
       "      (pp_block): TensorParallelColumnLinear(tp_rank=0, in_features=4096, out_features=128256, bias=False, unsharded_out_features=128256)\n",
       "    )\n",
       "    (cast_to_fp32): PipelineBlock(pp_rank=0)\n",
       "  )\n",
       "  (loss): PipelineBlock(\n",
       "    pp_rank=0\n",
       "    (pp_block): Loss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO(tj.solergibert) Comparar LlamaModel vs LlamaModel, nada de causal ni SFT!\n",
    "# TODO(tj.solergibert) Vale, ya lo estabamos haciendo.\n",
    "# TODO(tj.solergibert) Quedaria revisar lo de la LOSS, mierda. Tendremos que hacer una reduccion y usar la de pytorch\n",
    "# TODO(tj.solergibert) Para asegurarnos que todo bien Y LUEGO YA SI ESO LO DE LA MASK.\n",
    "hf_model.eval()\n",
    "nanotron_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = batch[\"input_ids\"].cuda()\n",
    "position_ids = batch[\"position_ids\"].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embedd = nanotron_model.model.token_position_embeddings(input_ids=input_ids, position_ids=position_ids)\n",
    "n_embedd[\"hidden_states\"] = n_embedd.pop(\"input_embeds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_embedd = hf_model.model.embed_tokens(input_ids)\n",
    "hf_position_embeddings = hf_model.model.rotary_emb(hf_embedd, position_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_close(n_embedd[\"hidden_states\"].transpose(0,1), hf_embedd) # TODO(tj.solergibert) Embeddings now are equal!\n",
    "assert_close(n_embedd[\"cos\"], hf_position_embeddings[0])\n",
    "assert_close(n_embedd[\"sin\"], hf_position_embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "n_hidden_encoder_states = nanotron_model.model.decoder[0](**n_embedd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_states': tensor([[[ 0.0014,  0.0040, -0.0050,  ...,  0.0093, -0.0007,  0.0005]],\n",
       " \n",
       "         [[ 0.0065,  0.0144,  0.0079,  ..., -0.0157, -0.0422, -0.0073]],\n",
       " \n",
       "         [[-0.0117, -0.0225,  0.0166,  ..., -0.0114, -0.0019,  0.0105]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.0205,  0.0003, -0.0043,  ..., -0.0337,  0.0027, -0.0114]],\n",
       " \n",
       "         [[ 0.0017, -0.0008,  0.0084,  ...,  0.0054,  0.0016,  0.0060]],\n",
       " \n",
       "         [[-0.0025, -0.0031, -0.0141,  ..., -0.0088,  0.0073,  0.0090]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, grad_fn=<AddBackward0>),\n",
       " 'position_ids': tensor([[  0,   1,   2,  ..., 576, 577, 578]], device='cuda:0',\n",
       "        dtype=torch.int32),\n",
       " 'cos': tensor([[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "          [ 0.5391,  0.6875,  0.7891,  ...,  1.0000,  1.0000,  1.0000],\n",
       "          [-0.4160, -0.0583,  0.2412,  ...,  1.0000,  1.0000,  1.0000],\n",
       "          ...,\n",
       "          [-0.4629, -0.4336,  0.5078,  ...,  1.0000,  1.0000,  1.0000],\n",
       "          [ 0.4941,  0.3574,  0.9297,  ...,  1.0000,  1.0000,  1.0000],\n",
       "          [ 1.0000,  0.9258,  0.9609,  ...,  1.0000,  1.0000,  1.0000]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'sin': tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 8.3984e-01,  7.2656e-01,  6.1719e-01,  ...,  3.6955e-06,\n",
       "            3.0100e-06,  2.4587e-06],\n",
       "          [ 9.1016e-01,  1.0000e+00,  9.6875e-01,  ...,  7.3910e-06,\n",
       "            6.0201e-06,  4.9174e-06],\n",
       "          ...,\n",
       "          [-8.8672e-01, -9.0234e-01, -8.6328e-01,  ...,  2.1362e-03,\n",
       "            1.7395e-03,  1.4114e-03],\n",
       "          [-8.6719e-01, -9.3359e-01, -3.6719e-01,  ...,  2.1362e-03,\n",
       "            1.7395e-03,  1.4191e-03],\n",
       "          [-5.2979e-02, -3.8086e-01,  2.8320e-01,  ...,  2.1362e-03,\n",
       "            1.7395e-03,  1.4191e-03]]], device='cuda:0', dtype=torch.bfloat16)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden_encoder_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "hf_hidden = hf_model.model.layers[0](hf_embedd, position_ids=position_ids, position_embeddings=hf_position_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0014,  0.0040, -0.0050,  ...,  0.0093, -0.0007,  0.0005],\n",
       "          [ 0.0064,  0.0146,  0.0078,  ..., -0.0157, -0.0425, -0.0073],\n",
       "          [-0.0117, -0.0225,  0.0167,  ..., -0.0115, -0.0018,  0.0106],\n",
       "          ...,\n",
       "          [ 0.0205,  0.0004, -0.0043,  ..., -0.0334,  0.0027, -0.0114],\n",
       "          [ 0.0017, -0.0008,  0.0084,  ...,  0.0054,  0.0016,  0.0061],\n",
       "          [-0.0025, -0.0032, -0.0141,  ..., -0.0087,  0.0073,  0.0090]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, grad_fn=<AddBackward0>),)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Tensor-likes are not close!\n\nMismatched elements: 1151415 / 7770112 (14.8%)\nGreatest absolute difference: 0.001953125 at index (0, 442, 3824) (up to 1e-05 allowed)\nGreatest relative difference: inf at index (0, 2, 2232) (up to 0.016 allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43massert_close\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_hidden_encoder_states\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhidden_states\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhf_hidden\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/testing/_comparison.py:1520\u001b[0m, in \u001b[0;36massert_close\u001b[0;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_layout, check_stride, msg)\u001b[0m\n\u001b[1;32m   1498\u001b[0m error_metas \u001b[38;5;241m=\u001b[39m not_close_error_metas(\n\u001b[1;32m   1499\u001b[0m     actual,\n\u001b[1;32m   1500\u001b[0m     expected,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1515\u001b[0m     msg\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m   1516\u001b[0m )\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_metas:\n\u001b[1;32m   1519\u001b[0m     \u001b[38;5;66;03m# TODO: compose all metas into one AssertionError\u001b[39;00m\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_metas[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto_error(msg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Tensor-likes are not close!\n\nMismatched elements: 1151415 / 7770112 (14.8%)\nGreatest absolute difference: 0.001953125 at index (0, 442, 3824) (up to 1e-05 allowed)\nGreatest relative difference: inf at index (0, 2, 2232) (up to 0.016 allowed)"
     ]
    }
   ],
   "source": [
    "assert_close(n_hidden_encoder_states[\"hidden_states\"].transpose(0,1), hf_hidden[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0014,  0.0040, -0.0050,  ...,  0.0093, -0.0007,  0.0005],\n",
       "         [ 0.0060,  0.0125,  0.0074,  ..., -0.0181, -0.0356, -0.0070],\n",
       "         [-0.0164, -0.0225,  0.0219,  ..., -0.0098, -0.0084,  0.0156],\n",
       "         ...,\n",
       "         [ 0.0121,  0.0106, -0.0149,  ..., -0.0229, -0.0056, -0.0021],\n",
       "         [ 0.0065,  0.0256, -0.0107,  ..., -0.0027, -0.0085,  0.0192],\n",
       "         [ 0.0025,  0.0199, -0.0267,  ..., -0.0056, -0.0045,  0.0182]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden_encoder_states[\"hidden_states\"].transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0014,  0.0040, -0.0050,  ...,  0.0093, -0.0007,  0.0005],\n",
       "         [ 0.0064,  0.0146,  0.0078,  ..., -0.0157, -0.0425, -0.0073],\n",
       "         [-0.0117, -0.0225,  0.0167,  ..., -0.0115, -0.0018,  0.0106],\n",
       "         ...,\n",
       "         [ 0.0205,  0.0004, -0.0043,  ..., -0.0334,  0.0027, -0.0114],\n",
       "         [ 0.0017, -0.0008,  0.0084,  ...,  0.0054,  0.0016,  0.0061],\n",
       "         [-0.0025, -0.0032, -0.0141,  ..., -0.0087,  0.0073,  0.0090]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_hidden[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    output_nanotron = nanotron_model.model(input_ids=batch[\"input_ids\"].cuda(), position_ids = batch[\"position_ids\"].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor(579, device='cuda:0', dtype=torch.int32)\n",
      "tensor([   0,  164,  443,  935, 1208, 1318, 1897], device='cuda:0',\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    output_hf = hf_model(input_ids=batch[\"input_ids\"].cuda(), position_ids = batch[\"position_ids\"].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.9688,  6.1562, 10.8750,  ..., -3.6406, -3.6406, -3.6406]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_hf.logits[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.9375,  6.0938, 10.7500,  ..., -3.6719, -3.6719, -3.6719]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_nanotron.transpose(0,1)[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Tensor-likes are not close!\n\nMismatched elements: 1143 / 128256 (0.9%)\nGreatest absolute difference: 0.5859375 at index (0, 12592) (up to 0.1 allowed)\nGreatest relative difference: 279.8438720703125 at index (0, 40526) (up to 0.1 allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assert_close\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# TODO(tj.solergibert) Ojo este test es solo de la position 0 jajajjajajajajajajaj\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43massert_close\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_hf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_nanotron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/testing/_comparison.py:1520\u001b[0m, in \u001b[0;36massert_close\u001b[0;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_layout, check_stride, msg)\u001b[0m\n\u001b[1;32m   1498\u001b[0m error_metas \u001b[38;5;241m=\u001b[39m not_close_error_metas(\n\u001b[1;32m   1499\u001b[0m     actual,\n\u001b[1;32m   1500\u001b[0m     expected,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1515\u001b[0m     msg\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m   1516\u001b[0m )\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_metas:\n\u001b[1;32m   1519\u001b[0m     \u001b[38;5;66;03m# TODO: compose all metas into one AssertionError\u001b[39;00m\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_metas[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto_error(msg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Tensor-likes are not close!\n\nMismatched elements: 1143 / 128256 (0.9%)\nGreatest absolute difference: 0.5859375 at index (0, 12592) (up to 0.1 allowed)\nGreatest relative difference: 279.8438720703125 at index (0, 40526) (up to 0.1 allowed)"
     ]
    }
   ],
   "source": [
    "from torch.testing import assert_close\n",
    "\n",
    "# TODO(tj.solergibert) Ojo este test es solo de la position 0 jajajjajajajajajajaj\n",
    "\n",
    "assert_close(output_hf.logits[:,0,:], output_nanotron.transpose(0,1)[:,0,:], rtol=1e-1, atol=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Tensor-likes are not close!\n\nMismatched elements: 217458927 / 243301632 (89.4%)\nGreatest absolute difference: 3.58984375 at index (0, 373, 33435) (up to 1e-05 allowed)\nGreatest relative difference: 1744897.0 at index (0, 1435, 64528) (up to 1.3e-06 allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43massert_close\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_hf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_nanotron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/testing/_comparison.py:1520\u001b[0m, in \u001b[0;36massert_close\u001b[0;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_layout, check_stride, msg)\u001b[0m\n\u001b[1;32m   1498\u001b[0m error_metas \u001b[38;5;241m=\u001b[39m not_close_error_metas(\n\u001b[1;32m   1499\u001b[0m     actual,\n\u001b[1;32m   1500\u001b[0m     expected,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1515\u001b[0m     msg\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m   1516\u001b[0m )\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_metas:\n\u001b[1;32m   1519\u001b[0m     \u001b[38;5;66;03m# TODO: compose all metas into one AssertionError\u001b[39;00m\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_metas[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto_error(msg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Tensor-likes are not close!\n\nMismatched elements: 217458927 / 243301632 (89.4%)\nGreatest absolute difference: 3.58984375 at index (0, 373, 33435) (up to 1e-05 allowed)\nGreatest relative difference: 1744897.0 at index (0, 1435, 64528) (up to 1.3e-06 allowed)"
     ]
    }
   ],
   "source": [
    "assert_close(output_hf.logits, output_nanotron.transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HF Model] Next token: 11415, probability: 0.10412170737981796\n",
      "[HF Model] Next token: 1523, probability: 0.04918361455202103\n",
      "[HF Model] Next token: 47032, probability: 0.043404385447502136\n",
      "[HF Model] Next token: 72514, probability: 0.03830423951148987\n",
      "[HF Model] Next token: 3493, probability: 0.03830423951148987\n",
      "[HF Model] Next token: 10477, probability: 0.03830423951148987\n",
      "[HF Model] Next token: 16805, probability: 0.03175532445311546\n",
      "[HF Model] Next token: 10552, probability: 0.026326090097427368\n",
      "[HF Model] Next token: 7664, probability: 0.021825095638632774\n",
      "[HF Model] Next token: 3041, probability: 0.018093638122081757\n"
     ]
    }
   ],
   "source": [
    "predicted_token = 34\n",
    "\n",
    "next_tokens_hf = torch.softmax(output_hf.logits[0, predicted_token, :], -1)\n",
    "hf_topk_next_tokens= torch.topk(next_tokens_hf, 10)\n",
    "\n",
    "\n",
    "print(*[f\"[HF Model] Next token: {idx.item()}, probability: {prob}\" for idx, prob in zip(hf_topk_next_tokens.indices, hf_topk_next_tokens.values)], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nanotron Model] Next token: 11415, probability: 0.10305546224117279\n",
      "[Nanotron Model] Next token: 1523, probability: 0.048679955303668976\n",
      "[Nanotron Model] Next token: 47032, probability: 0.04295990616083145\n",
      "[Nanotron Model] Next token: 10477, probability: 0.04035709798336029\n",
      "[Nanotron Model] Next token: 3493, probability: 0.04035709798336029\n",
      "[Nanotron Model] Next token: 72514, probability: 0.03791198879480362\n",
      "[Nanotron Model] Next token: 16805, probability: 0.031430136412382126\n",
      "[Nanotron Model] Next token: 10552, probability: 0.027737000957131386\n",
      "[Nanotron Model] Next token: 7664, probability: 0.02299478091299534\n",
      "[Nanotron Model] Next token: 3041, probability: 0.017908351495862007\n"
     ]
    }
   ],
   "source": [
    "next_tokens_nanotron = torch.softmax(output_nanotron.transpose(0,1)[0, predicted_token, :], -1)\n",
    "nanotron_topk_next_tokens= torch.topk(next_tokens_nanotron, 10)\n",
    "\n",
    "\n",
    "print(*[f\"[Nanotron Model] Next token: {idx.item()}, probability: {prob}\" for idx, prob in zip(nanotron_topk_next_tokens.indices, nanotron_topk_next_tokens.values)], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Nanotron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nanotron.parallel.parameters import sanity_check\n",
    "\n",
    "sanity_check(root_module=nanotron_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving weights: 100%|██████████| 195/195 [00:41<00:00,  4.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from nanotron.serialize import save_meta, save_weights, TrainingMetadata\n",
    "from nanotron.serialize.metadata import DataStageMetadata\n",
    "\n",
    "out_path = \"/mloscratch/homes/solergib/converter/nanotron/n_c/first/\"\n",
    "out_path = Path(out_path)\n",
    "\n",
    "save_weights(model=nanotron_model, parallel_context=parallel_context, root_folder=out_path)\n",
    "\n",
    "training_metadata = TrainingMetadata(last_train_step=0, consumed_train_samples=0, data_stages=[DataStageMetadata(name=\"Empty\", consumed_train_samples=0, start_training_step=0)])\n",
    "\n",
    "save_meta(root_folder=out_path, parallel_context=parallel_context, training_metadata=training_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving config ...\n",
      "Saving model config ...\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import yaml\n",
    "from nanotron.config import GeneralArgs, ModelArgs, TokenizerArgs, Config\n",
    "from nanotron.config.models_config import ExistingCheckpointInit\n",
    "from dataclasses import asdict\n",
    "\n",
    "with open(out_path / \"config.yaml\", \"w\") as f:\n",
    "    config = Config(\n",
    "        general=GeneralArgs(project=\"conversion\", run=\"Llama3-8B\"),\n",
    "        parallelism=parallel_config,\n",
    "        model=ModelArgs(\n",
    "            init_method=ExistingCheckpointInit(out_path),\n",
    "            model_config=nanotron_config,\n",
    "        ),\n",
    "        tokenizer=TokenizerArgs(PATH_TO_LLAMA),\n",
    "    )\n",
    "    print(\"Saving config ...\")\n",
    "    yaml.dump(config.as_dict(), f)\n",
    "\n",
    "with open(out_path / \"model_config.json\", \"w\") as f:\n",
    "    print(\"Saving model config ...\")\n",
    "    json.dump(asdict(nanotron_config), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mloscratch/homes/solergib/SFT/transformers/src/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[27, 22,  0, 97, 13, 49, 56, 35, 70, 91, 38, 30, 26, 94, 68, 46, 89, 32,\n",
      "         70, 85, 50, 67, 70, 86, 66, 82, 18, 72, 27, 37, 91, 27, 60, 57, 23, 93,\n",
      "         10, 80, 82, 26, 13, 50, 12, 68, 63, 85, 55,  1,  3, 61, 37, 70, 12, 97,\n",
      "          1, 59, 90, 45, 74, 62, 66, 54, 94, 18, 54, 89, 49,  3, 66, 55]],\n",
      "       device='cuda:0'), 'position_ids': tensor([[0, 0, 1, 0, 1, 2, 0, 1, 2, 3, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 5, 0, 1, 2,\n",
      "         3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5,\n",
      "         6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6]],\n",
      "       device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/mloscratch/homes/solergib/SFT/transformers\")\n",
    "\n",
    "import torch\n",
    "from t_tests.models.llama.test_modeling_llama import LlamaModelTester\n",
    "\n",
    "lmt = LlamaModelTester(parent=None)\n",
    "\n",
    "_, inputs_dict = lmt.prepare_config_and_inputs_for_common()\n",
    "dummy_attention_mask = inputs_dict[\"attention_mask\"]\n",
    "inputs_dict[\"input_ids\"][~dummy_attention_mask.bool()] = 0\n",
    "\n",
    "padfree_inputs_dict = {\n",
    "    k: v[dummy_attention_mask.bool()].unsqueeze(0)\n",
    "    for k, v in inputs_dict.items()\n",
    "    if not k == \"attention_mask\"\n",
    "}\n",
    "\n",
    "padfree_inputs_dict[\"position_ids\"] = (\n",
    "    torch.cat([torch.arange(length) for length in dummy_attention_mask.sum(1).tolist()])\n",
    "    .long()\n",
    "    .unsqueeze(0)\n",
    "    .to(\"cuda\")\n",
    ")\n",
    "\n",
    "print(padfree_inputs_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
